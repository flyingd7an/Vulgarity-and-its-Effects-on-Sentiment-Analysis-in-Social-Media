# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hfSTAujzjOsbPebIIi3FbIvUIwrBqpHi
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Load the dataset
data = pd.read_csv('noswearingclean.csv')  # Replace 'dataset.csv' with your actual dataset file

# Split the data into training and testing sets
X = data['Word']  # Column containing the text data
y = data['Type']  # Column containing the labels

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create TF-IDF vectorizer
vectorizer = TfidfVectorizer()
X_train_vectorized = vectorizer.fit_transform(X_train)
X_test_vectorized = vectorizer.transform(X_test)

# Train the logistic regression model
model = LogisticRegression()
model.fit(X_train_vectorized, y_train)

# Predict labels for the test set
y_pred = model.predict(X_test_vectorized)

# Calculate evaluation metrics
report = classification_report(y_test, y_pred, output_dict=True)
f1_score = report['macro avg']['f1-score']
accuracy = accuracy_score(y_test, y_pred)
precision, recall, _, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')

# Print the evaluation metrics
print(f'F1 Score: {f1_score:.2f}')
print(f'Accuracy: {accuracy:.2f}')
print(f'Precision: {precision:.2f}')
print(f'Recall: {recall:.2f}')
# Create a DataFrame for the evaluation metrics
metrics_df = pd.DataFrame({'Metric': ['F1 Score', 'Accuracy', 'Precision', 'Recall'],
                           'Score': [f1_score, accuracy, precision, recall]})

# Print the table
print("Evaluation Metrics:\n")
print(metrics_df)
print("\n")

# Create a bar plot of the evaluation metrics
plt.figure(figsize=(8, 5))
plt.bar(metrics_df['Metric'], metrics_df['Score'], color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
plt.title('Evaluation Metrics')
plt.xlabel('Metric')
plt.ylabel('Score')
plt.ylim([0, 1])
plt.show()